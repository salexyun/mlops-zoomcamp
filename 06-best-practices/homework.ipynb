{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ee32618-1034-4d94-9197-cb0735bc2e2d",
   "metadata": {},
   "source": [
    "# Homework 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9461d8-b7f2-4bb0-af00-f37dd36f668b",
   "metadata": {},
   "source": [
    "## Q1. Refactoring\n",
    "\n",
    "Before we can start covering our code with tests, we need to refactor it. We'll start by getting rid of all the global variables.\n",
    "\n",
    "* Let's create a function `main` with two parameters: `year` and `month`\n",
    "* Move all the code (except `read_data`) inside `main`\n",
    "* Make `categorical` a parameter for `read_data` and pass it inside `main`\n",
    "Now we need to create the \"main\" block from which we'll invoke the main function. How does the `if` statement that we use for this looks like?\n",
    "\n",
    "**predicted mean duration: 14.203865642696083**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee250d27-1ea6-44ee-8c2c-61fab1f712f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/mlops/lib/python3.12/site-packages/sklearn/base.py:347: InconsistentVersionWarning: Trying to unpickle estimator DictVectorizer from version 1.5.0 when using version 1.3.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/mlops/lib/python3.12/site-packages/sklearn/base.py:347: InconsistentVersionWarning: Trying to unpickle estimator LinearRegression from version 1.5.0 when using version 1.3.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "predicted mean duration: 14.203865642696083\n"
     ]
    }
   ],
   "source": [
    "!python batch.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137c79d2-58e8-4987-a46b-97276b40fc34",
   "metadata": {},
   "source": [
    "## Q2. Installing pytest\n",
    "\n",
    "Now we need to install `pytest`\n",
    "\n",
    "Next, create a folder `tests` and create two files. One will be the file with tests. We can name it `test_batch.py`.\n",
    "\n",
    "What should be the other file?\n",
    "\n",
    "**hello**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2006bbf7-2984-4f42-8f10-084ce0e651d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCreating a virtualenv for this project...\u001b[0m\n",
      "Pipfile: \u001b[33m\u001b[1m/workspaces/mlops-zoomcamp/06-best-practices/Pipfile\u001b[0m\n",
      "\u001b[1mUsing\u001b[0m \u001b[33m\u001b[1m/usr/local/python/3.10.13/bin/python\u001b[0m \u001b[32m(3.10.13)\u001b[0m \u001b[1mto create virtualenv...\u001b[0m\n",
      "\u001b[2K\u001b[32m⠴\u001b[0m Creating virtual environment...\u001b[36mcreated virtual environment CPython3.10.13.final.0-64 in 1453ms\n",
      "  creator CPython3Posix(dest=/home/codespace/.local/share/virtualenvs/06-best-practices-EhTA5YkS, clear=False, no_vcs_ignore=False, global=False)\n",
      "  seeder FromAppData(download=False, pip=bundle, setuptools=bundle, wheel=bundle, via=copy, app_data_dir=/home/codespace/.local/share/virtualenv)\n",
      "    added seed packages: pip==24.0, setuptools==70.0.0, wheel==0.43.0\n",
      "  activators BashActivator,CShellActivator,FishActivator,NushellActivator,PowerShellActivator,PythonActivator\n",
      "\u001b[0m\n",
      "✔ Successfully created virtual environment!\n",
      "\u001b[2K\u001b[32m⠴\u001b[0m Creating virtual environment...\n",
      "\u001b[1A\u001b[2K\u001b[32mVirtualenv location: /home/codespace/.local/share/virtualenvs/06-best-practices-EhTA5YkS\u001b[0m\n",
      "\u001b[1;32mInstalling pytest\u001b[0m\u001b[1;33m...\u001b[0m\n",
      "\u001b[?25lResolving pytest\u001b[33m...\u001b[0m\n",
      "\u001b[2K\u001b[1mAdded \u001b[0m\u001b[1;32mpytest\u001b[0m to Pipfile's \u001b[1;33m[\u001b[0m\u001b[33mdev-packages\u001b[0m\u001b[1;33m]\u001b[0m \u001b[33m...\u001b[0m\n",
      "\u001b[2K✔ Installation Succeeded...\n",
      "\u001b[2K\u001b[32m⠋\u001b[0m Installing pytest...\n",
      "\u001b[1A\u001b[2K\u001b[1;33mPipfile.lock \u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33meaed16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m out of date, updating to \u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33mc6a14e\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m...\u001b[0m\n",
      "Locking\u001b[0m \u001b[33m[packages]\u001b[0m dependencies...\u001b[0m\n",
      "\u001b[?25lBuilding requirements\u001b[33m...\u001b[0m\n",
      "\u001b[2KResolving dependencies\u001b[33m...\u001b[0m\n",
      "\u001b[2K✔ Success! Locking...\n",
      "\u001b[2K\u001b[32m⠏\u001b[0m Locking...\n",
      "\u001b[1A\u001b[2KLocking\u001b[0m \u001b[33m[dev-packages]\u001b[0m dependencies...\u001b[0m\n",
      "\u001b[?25lBuilding requirements\u001b[33m...\u001b[0m\n",
      "\u001b[2KResolving dependencies\u001b[33m...\u001b[0m\n",
      "\u001b[2K✔ Success! Locking...\n",
      "\u001b[2K\u001b[32m⠙\u001b[0m Locking...\n",
      "\u001b[1A\u001b[2K\u001b[1mUpdated Pipfile.lock (2fbd939eb727a20acf1455cb0982b7353612177714f34dba0a6915ff6cc6a14e)!\u001b[0m\n",
      "\u001b[1mInstalling dependencies from Pipfile.lock \u001b[0m\u001b[1m(\u001b[0m\u001b[1mc6a14e\u001b[0m\u001b[1m)\u001b[0m\u001b[1;33m...\u001b[0m\n",
      "\u001b[1mInstalling dependencies from Pipfile.lock \u001b[0m\u001b[1m(\u001b[0m\u001b[1mc6a14e\u001b[0m\u001b[1m)\u001b[0m\u001b[1;33m...\u001b[0m\n",
      "To activate this project's virtualenv, run \u001b[33mpipenv shell\u001b[0m.\n",
      "Alternatively, run a command inside the virtualenv with \u001b[33mpipenv run\u001b[0m.\n"
     ]
    }
   ],
   "source": [
    "!pipenv install --dev pytest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2288971-2192-435a-968e-42d575e15280",
   "metadata": {},
   "source": [
    "## Q3. Writing first unit test\n",
    "\n",
    "Now let's cover our code with unit tests. We'll start with the pre-processing logic inside `read_data`. It's difficult to test right now because first reads the file and then performs some transformations. We need to split this code into two parts: reading (I/O) and transformation. So let's create a function `prepare_data` that takes in a dataframe (and some other parameters too) and applies some transformation to it (that's basically the entire `read_data` function after reading the parquet file). Define the expected output and use the assert to make sure that the actual dataframe matches the expected one.\n",
    "\n",
    "How many rows should be there in the expected dataframe?\n",
    "* **2**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f04fe2-6d1f-4a8f-bc06-c2a1d05e7f9c",
   "metadata": {},
   "source": [
    "## Q4. Mocking S3 with Localstack\n",
    "\n",
    "Now let's prepare for an integration test. In our script, we write data to S3. So we'll use Localstack to mimic S3.\n",
    "\n",
    "First, let's run Localstack with Docker compose. Let's create a `docker-compose.yaml` file with just one service: localstack. Inside localstack, we're only interested in running S3. Start the service and test it by creating a bucket where we'll keep the output. Let's call it \"nyc-duration\".\n",
    "\n",
    "With AWS CLI, we create a bucket. Then we need to check that the bucket was successfully created. In both cases we should adjust commands for localstack. What option do we need to use for such purposes?\n",
    "* `--backend-store-uri`\n",
    "* `--profile`\n",
    "* `--endpoint-url`\n",
    "* `--version`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec574135-a023-4c3b-b549-28de4ea5cc98",
   "metadata": {},
   "source": [
    "## Q5. Creating test data\n",
    "\n",
    "Now let's create `integration_test.py`\n",
    "\n",
    "We'll use the dataframe we created in Q3 (the dataframe for the unit test) and save it to S3. You don't need to do anything else: just create a dataframe and save it.\n",
    "\n",
    "We will pretend that this is data for January 2023.\n",
    "\n",
    "Run the `integration_test.py` script. After that, use AWS CLI to verify that the file was created.\n",
    "\n",
    "What's the size of the file?\n",
    "* **3620**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0da4ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws --endpoint-url=\"http://localhost:4566\" s3://nyc-duration/in/2023-01.parquet --recursive --human-readable --summarize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfb3a3d-c4c7-469b-a8d6-6ded8031a8aa",
   "metadata": {},
   "source": [
    "## Q6. Finish the integration test\n",
    "\n",
    "We can read from our localstack s3, but we also need to write to it.\n",
    "\n",
    "Create a function `save_data` which works similarly to `read_data`, but we use it for saving a dataframe.\n",
    "\n",
    "Let's run the `batch.py` script for January 2023 (the fake data we created in Q5).\n",
    "\n",
    "We can do that from our integration test in Python: we can use `os.system` for doing that (there are other options too).\n",
    "\n",
    "Now it saves the result to localstack.\n",
    "\n",
    "The only thing we need to do now is to read this data and verify the result is correct.\n",
    "\n",
    "What's the sum of predicted durations for the test dataframe?\n",
    "* **36.28**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
